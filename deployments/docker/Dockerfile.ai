
# Dockerfile for OVASABI AI Python service
# Use a specific, up-to-date slim image

FROM python:3.11.9-slim-bookworm AS builder

WORKDIR /ai

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
  build-essential \
  libpq-dev \
  protobuf-compiler


# Install Python dependencies (cache layer)
COPY internal/ai/python/requirements.txt ./
# Force protobuf<4 regardless of requirements.txt resolution
RUN --mount=type=cache,target=/root/.cache/pip \
  pip install --upgrade pip && \
  pip install --no-cache-dir --upgrade setuptools wheel && \
  pip install --no-cache-dir -r requirements.txt && \
  pip install --no-cache-dir 'protobuf<4' && \
  pip install --no-cache-dir wasmtime grpcio-tools



# Copy Python source code (after deps for cache efficiency, flattened)
COPY internal/ai/python /ai/python

# --- Resource limits for AI engine ---
# Limit Python, numpy, torch, OpenBLAS, and thread usage to 1/4 of available CPUs
ENV OMP_NUM_THREADS=2
ENV OPENBLAS_NUM_THREADS=2
ENV MKL_NUM_THREADS=2
ENV NUMEXPR_NUM_THREADS=2
ENV VECLIB_MAXIMUM_THREADS=2
ENV NUMBA_NUM_THREADS=2
ENV PYTORCH_NUM_THREADS=2
ENV TF_NUM_INTEROP_THREADS=2
ENV TF_NUM_INTRAOP_THREADS=2
ENV TRANSFORMERS_NUM_THREADS=2

# Optionally, set Python concurrency limits in code (see below)



# --- Model Download Stage (for optimal caching) ---
FROM python:3.11.9-slim-bookworm AS model-downloader
WORKDIR /modelstage
RUN pip install --no-cache-dir 'huggingface_hub[cli]'
RUN mkdir -p /modelstage/models
RUN huggingface-cli download Mungert/Phi-4-mini-instruct.gguf \
  --include "phi-4-mini-q4_k_s.gguf" --local-dir /modelstage/models


# --- Final runtime image ---
FROM python:3.11.9-slim-bookworm

WORKDIR /ai

# Install only runtime dependencies (use libpq5 instead of libpq-dev for smaller surface)
RUN apt-get update && apt-get install -y --no-install-recommends libpq5 && rm -rf /var/lib/apt/lists/*

# Copy installed Python packages and built code from builder (flattened)
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /ai/python /ai/python
# Copy model from model-downloader stage
COPY --from=model-downloader /modelstage/models /ai/python/models

ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/ai/python

RUN useradd -m ai && chown -R ai /ai
USER ai

CMD ["python", "-m", "python.main"]
